# 北大未名BBS爬虫

本项目旨在抓取并归档北京大学未名BBS论坛上某一版面下的所有帖子内容及其附件，并生成一批html，方便非技术用户离线浏览和保存。项目代码基本通过拷打Gemini完成。

暂不支持用户登录。因此，一些版面可能无法查看。另外，由于一些版面在不登录的情况下只能在北大校园网下访问，建议在校园网环境下使用该爬虫。

## 设置

1.  **创建虚拟环境**
    建议使用虚拟环境来管理依赖项。
    ```bash
    python -m venv venv
    source venv/bin/activate
    ```

2.  **安装依赖**
    使用 pip 安装所需的 Python 库：
    ```bash
    pip install -r requirements.txt
    ```

## 配置

在运行爬虫之前，可以编辑 `config.py` 文件来设置所需的参数。主要用到的参数有：

-   `BOARD_ID`：希望抓取的版面数字 ID（例如，"MANYATTA 蒙养山人类学学社" 版面为 `1090`。此版面帖子数量较少，可以用于测试）。
-   `RUN_MODE`：操作模式。
    -   `'overwrite'`：从头开始抓取整个版面。
    -   `'update'`：仅抓取自上次运行以来新增或更新的帖子。

## 使用方法

该爬虫设计为通过终端按一系列独立的步骤运行，分为四步。

### 步骤 1：抓取版面索引

此步骤逐页读取版面的目录页，以获取版面上所有帖子的列表，并将其元数据保存到 `output/$BOARD_ID` 目录中的 CSV 文件。

```bash
python -m scraper.step_1_index --board_id 1090 --mode overwrite
```
可选参数（下面其他步骤都一样）：
-   `--board_id`：（可选）覆盖 `config.py` 中的 `BOARD_ID`。
-   `--mode`：（可选）覆盖 `config.py` 中的 `RUN_MODE`。

### 步骤 2：抓取单个帖子

此步骤读取步骤 1 中创建的 CSV 文件，然后抓取每个帖子的内容，并将其保存为 JSON 文件。这包含了除附件文件之外的所有文本和元数据，可用于纯文本分析。这些文件保存在 `output/$BOARD_ID/jsons/` 目录中。

```bash
python -m scraper.step_2_thread
```

由于一些帖子中内置的图片是以base64编码嵌入在正文中的（包括主贴和评论），而不是像普通附件那样单独存储，因此这些图片会直接包含在 JSON 文件中。这会导致获取速度比较慢，且生成的 JSON 文件体积较大。

### 步骤 3：下载附件（可跳过）

这一步下载所有帖子的所有普通附件（如图片、文档等），并将它们保存在 `output/$BOARD_ID/attachments/` 目录中。附件一般比较大，因此此步骤可选。

```bash
python -m scraper.step_3_download_attachments
```

### 步骤 4：渲染 HTML

最后，将json内容渲染成 HTML 文件以供查看。另外，这一步还会创建一个主 `index.html` 文件，以及按年份归档的帖子目录，用于浏览所有归档帖子。

```bash
python -m scraper.step_4_render
```

-   此步骤完成后，您可以在浏览器中打开 `output/$BOARD_ID/html/index.html` 来查看归档。

## 可能存在的问题

- 在`update`模式下，如果一个此前存在的帖子内部的正文或评论被编辑过，可能无法被检测到，因为目前的实现仅通过帖子列表中的回复数量和最后回复（的发表）时间来判断帖子是否有更新。

- 如果在程序运行步骤1生成`csv`索引的过程中，恰好有人发新帖，或挖旧坟，导致每页的内容有错位，可能导致帖子遗漏或重复。
